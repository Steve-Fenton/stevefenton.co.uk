---
title: Software Delivery Research
navOrder: 2000
pubDate: 2024-05-01
modDate: 2025-06-12
keywords: software,delivery,research
description: Research-related publications and updates.
---

We have solidly moved into the era of research-backed software delivery. Over the past ten years, we've learned a great deal about what works and what doesn't. We no longer depend solely on *strong voices* as we now have *solid data*.

My favourite research efforts are:

- The [Accelerate State of DevOps Report](https://dora.dev/research/) from [DORA](https://dora.dev/)
- The [State of CI/CD Report](https://cd.foundation/reports/) from the [CD Foundation](https://cd.foundation/) and [SlashData](https://www.slashdata.co/)

But also, I'm a naturally curious person. That means I ask questions to find out more about how we're all delivering software. For this reason, I'll be running some research to find out more about how we're all working.

## The State of GitOps report

I lead a research effort to understand GitOps adoption, practices, and outcomes. The results are based on 660 survey responses and interviews with expert practitioners.

The report covers topics such as:

- What good GitOps looks like
- Current industry adoption of GitOps
- Future plans for GitOps
- The relationship between GitOps and DevOps
- The benefits of GitOps
- Which GitOps practices drive outcomes

The report is likely to come out in **June 2025**. Sign up to get a free copy of [the state of GitOps report](https://octopus.com/publications/state-of-gitops-report). 

## Platform Engineering

I'm working with Saim Safdar, host of [the Cloud Native Podcast](https://www.youtube.com/@cloudnativefm) to find out the business and technical motivations for Platform Engineering.

Our plan is to:

- (Done!) Speak to practitioners to find out key motivations for internal developer platforms
- (Done!) Design a survey based on what we learn
- (Done!) Run the survey to get a broad picture of Platform Engineering
- Product a mini-report based on what we learn
- Extend this by adjusting our survey instrument and getting a broader sample

By collaborating on this project, we hope create an independent research effort and I'm sure our findings will make it into our writing, podcasts, and webinars.

We have our first batch of survey responses and we'll be analyzing them and sharing results soon!

## Get updates

I've created a [research-only mailing list](https://oc.to/research-updates) for folks who want to stay updated.

<iframe width="540" height="305" src="https://sibforms.com/serve/MUIFAPDnrZI-NoozGdJ2Yl2sW4ZeTb_IP2vOOEBZwCYhS8DA-LNQHnccCfJyxElaWZM8h104CRnTJW7aqE3IRwvi58V9m3Ns8nzZmCcbW2QbGkvBvj3a4gYpQ9erVOE6BZ-P6VZh_1xfej8huScT4cDHmS2ROUX4miuJ-NsVczdZP-2mpFkCWDCuY_pybOOZ0H4GxAOEVxGK7ijs" frameborder="0" scrolling="auto" allowfullscreen style="display: block;margin-left: auto;margin-right: auto;width: 100%;"></iframe>

## Frequently asked questions

This is a bit like a frequently asked questions section, except it's more like a frequently misunderstood concepts section. Hopefully it's useful.

### Can I have the source data?

No. When I collect survey data, I promise people I won't share it. There are usually enough bits in the survey data that you could reverse engineer it and either identify companies and individuals, or mis-identify them. That means the data must be kept securely and I can't share it. If you want to test the results, I can give you the questions and you can collect your own data in a responsible way. I'd definitely be interested in hearing what you find if you do this, in fact it might become a condition of getting the questions that you report back to tell me how it went.

### Where has the survey come from?

This is a crucial question to ask with all surveys and reports. My natural curiosity is the source of all my research, though some of my research is paid for by my employer. I'm not a fan of "9 out of 10 cats" research, because it's really marketing in disguise. To avoid falling into this trap, all my research starts with a number of hypotheses to test. I faithfully note down whether they are confirmed or busted, because research is exciting either way.

### What questions does the survey ask?

I take great care to ask questions that eliminate bias, depend on knowledge respondents might not have, or that lead the respondents. This is the great challenge of survey design and I'm refining my skills here all the time. I usually share at least some of the questions alongside reports. Contact me if you want questions from one of the reports I've worked on and we can talk.

### How many people were asked?

I usually put this number in a prominent place on a full report. In addition to trying to get lots of responses, I try to make sure they are from people who are representative of the population I'm attempting to measure. My aim is to get a large enough sample that I can segment the responses by various factors and still have a decent chunk in each segment.

### Are the claims reasonable?

The hype wore me down a long time ago. I'm not interested in creating click bait or outrageous claims. When I find something surprising, I muffle my excitement long enought to reflect on what I might have missed. I also work with other people so they can check my work.

### How would you describe your research?

I'm not a scientist. I'm a software delivery practitioner who is deeply interested in research. In fact, I think we should be testing more of the ideas that people claim are great as many of them clearly aren't any good. Instead of depending on beardy white dudes to sprinkle their ancient wisdom on us, we can investigate their experience and test the techniques and practices they recommend. We'll all be better off this way.

What I do bring to the party is decades of experience working with data and some Python chops for data analysis.
