---
title: Pragmatic AI discussions
navMenu: false
pubDate: 2025-08-12
modDate: 2025-08-17
keywords: ai,artificial intelligence,machine learning
description: Here are the terms under which I'm discussing AI. If I'm not responding to your tangential debates, it's likely due to this.
bannerImage:
    src: /img/topic/abstract/ai.png
    alt: A computer generated fractal on a computer generated cloud background.
authors:
    - steve-fenton
categories:
    - Opinion
tags:
    - AI
---

There's no doubt about it, we need to talk about AI. Many dimensions need to be discussed, and the wiring between these dimensions is getting crossed. The problem is, AI is a trigger subject, and you end up trapped between the sabot-wielding righteous and the foaming-at-the-mouth robot overlord devotees.

You can [skip straight to the framework](#ai-discussion-framework) if you don't want to read the reasons behind it.

## The need for terms of engagement

So, we need some terms of engagement that let us talk about the middle. I don't want to dismiss the ethical and moral concerns. Many of them are valid, and someone must determine how to resolve the various conflicts. The hype machine I'm less tolerant of, but if you want to be super-excited about AI and imagine some quite extravagant claims about what it can do, go ahead and be your own joy.

The problem is, you can't talk about the practical everyday work when each conversation gets redirected to extremesville.

I've [promised never to use AI for my writing, art, or music](https://stevefenton.co.uk/blog/2023/02/facing-reality-ai/). My personal choice is that I'd rather give the world bad writing, art, and music that comes from my soul. You know I've kept my promise if you've seen my cartoons.

I bought a book and [returned it because it was written by AI](https://stevefenton.co.uk/blog/2025/01/generated-books/). I definitely don't want people to pass off AI-generated work as their own. I'm not too sure about the forthcoming book project that the author has told us was written using AI. But I don't want to discuss these things. That's the point of this post.

## Not for art, but for yawn-work

When I'm writing a Python function to display a chart and need to remove splines and change the font, I'd rather use coding assistance than <abbr title="read the fucking manual">RTFM</abbr>.

You see, I remember when text editors started highlighting syntax. It was brilliant. Then I remember when they added auto-complete, made auto-complete context-aware, and suggested the most likely auto-complete instead of an alphabetical list. I've used these funny shortcuts in IDEs where you type `testc` and hit tab, and it scaffolds out a whole test class, so you didn't have to.

I was allowed to talk about these in a way that's impossible in the current polarised and jumpy situation around AI.

## I share your feelings

I share your concerns. I agree! These billionaires are disconnected from reality and seemingly immune to any government intervention to reconnect them. I'm concerned about the power demands, the water use, and the unfair use of people's content.

Despite this, we need to build a safe space to talk about the practical application of these tools. So, I'm creating a page (it's this page) that I can point to with my terms of engagement for this discussion. This is my sign for that "don't make me tap the sign" moment.

You can use it, too. And it's in a [Git repo](https://github.com/Steve-Fenton/stevefenton.co.uk/blob/main/src/pages/blog/2025/08/pragmatic-ai-discussions.md) that you can use if you want to collaborate with me in good faith. You can raise an issue or suggest an edit as long as it's in the spirit of this post.

## AI discussion framework

This framework for AI discussion can be used to guide a productive discussion on using these tools.

*We acknowledge the broader concerns about this technology, but will focus today on its practical use.*

1. **Stay on topic**: Discuss actual usage without derailing into unresolved systemic issues.
2. **Acknowledge harm**: We recognize unresolved ethical and moral ~~problems~~ in AI training and operation.
3. **Consider climate impact**: Environmental costs matter, especially given current climate crisis.
4. **Check enthusiasm**: Some people overestimate AI capabilities; we'll stay grounded.
5. **Define "productivity"**: We'll be specific about outcomes rather than using vague productivity claims.

### What We Discuss

- **Tools and techniques**: Which tools, how you use them, what works/fails.
- **Human oversight**: How you balance automation with human involvement.
- **Specific ethics**: Legality and appropriateness of particular use cases.

### The Razor

For complex ethical debates: **Are the people who could solve this problem in the room?** If not, acknowledge the issue and move on to actionable discussion.
