---
title: Pragmatic AI discussions
navMenu: false
pubDate: 2025-08-12
modDate: 2025-08-12
keywords: ai,artificial intelligence,machine learning
description: Here are the terms under which I'm discussing AI. If I'm not responding to your tangential debates, it's likely due to this.
bannerImage:
    src: /img/topic/abstract/ai.png
    alt: A computer generated fractal on a computer generated cloud background.
authors:
    - steve-fenton
categories:
    - Opinion
tags:
    - AI
---

There's no doubt about it, we need to talk about AI. Many dimensions need to be discussed, and the wiring between these dimensions is getting crossed. The problem is, AI is a trigger subject, and you end up trapped between the sabot-wielding righteous and the foaming-at-the-mouth robot overlord devotees.

## The need for terms of engagement

So, we need some terms of engagement that let us talk about the middle. I don't want to dismiss the ethical and moral concerns. Many of them are valid, and someone must determine how to resolve the various conflicts. The hype machine I'm less tolerant of, but if you want to be super-excited about AI and imagine some quite extravagant claims about what it can do, go ahead and be your own joy.

The problem is, you can't talk about the practical everyday work when each conversation gets redirected to extremesville.

I've [promised never to use AI for my writing, art, or music](https://stevefenton.co.uk/blog/2023/02/facing-reality-ai/). My personal choice is that I'd rather give the world bad writing, art, and music that comes from my soul. You know I've kept my promise if you've seen my cartoons.

I bought a book and [returned it because it was written by AI](https://stevefenton.co.uk/blog/2025/01/generated-books/). I definitely don't want people to pass off AI-generated work as their own. I'm not too sure about the forthcoming book project that the author has told us was written using AI. But I don't want to discuss these things. That's the point of this post.

## Not for art, but for yawn-work

When I'm writing a Python function to display a chart and need to remove splines and change the font, I'd rather use coding assistance than <abbr title="read the fucking manual">RTFM</abbr>.

You see, I remember when text editors started highlighting syntax. It was brilliant. Then I remember when they added auto-complete, made auto-complete context-aware, and suggested the most likely auto-complete instead of an alphabetical list. I've used these funny shortcuts in IDEs where you type `testc` and hit tab, and it scaffolds out a whole test class, so you didn't have to.

I was allowed to talk about these in a way that's impossible in the current polarised and jumpy situation around AI.

## I share your feelings

I share your concerns. I agree! These billionaires are disconnected from reality and seemingly immune to any government intervention to reconnect them. I'm concerned about the power demands, the water use, and the unfair use of people's content.

Despite this, we need to build a safe space to talk about the practical application of these tools. So, I'm creating a page (it's this page) that I can point to with my terms of engagement for this discussion. This is my sign for that "don't make me tap the sign" moment.

You can use it, too. And it's in a [Git repo](https://github.com/Steve-Fenton/stevefenton.co.uk/blob/main/src/pages/blog/2025/08/pragmatic-ai-discussions.md) that you can use if you want to collaborate with me in good faith. You can raise an issue or suggest an edit as long as it's in the spirit of this post.

## Pragmatic limits on the discussion of applying AI tools to our work

Here are the terms under which I'm discussing AI. If I'm not responding to your tangential debates, it's likely due to this.

1. We want to talk to other people about how they use this technology, and how we use it, without being hauled off topic by the concerns we list and acknowledge below.
2. We acknowledge the ethical and moral problems involved in the training and operation of this technology by vendors, which are yet to be resolved.
3. We agree that the environmental impact of this technology must be considered, especially now when we are already experiencing climate change.
4. We understand some people are very excited about this technology, possibly even beyond its capabilities.
5. We will be responsible when we talk about "productivity," as this is not a useful measure of the outcomes of this technology.

What's still part of the discussion.

- What tools you use
- How you use them, what works, what doesn't
- How you balance the automation with human involvement and oversight
- The ethicality of specific uses (for example, using it to do something illegal, like fraud)

The ethicality part is complex, thanks to the vendors being so careless. I get that. There's a good razor to use for all this debate that can help decide if it's in or out.

> Are the people who could solve that in the room?
